{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "3a7e2c83-e94d-40c7-936e-e789ce743289",
   "metadata": {},
   "source": [
    "# Machine Learning Model Notebook for On-Device Machine Learning for vibration based predictive maintainance of industrial induction motors using MEMS sensors."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b9623ab0-3817-4c3e-9f90-497d6eb8c3ef",
   "metadata": {},
   "source": [
    "### imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "5b38515a-d160-4880-81eb-3c879ac519a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import random\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import tensorflow as tf\n",
    "\n",
    "from glob import glob\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler, LabelEncoder\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "from tensorflow.keras import regularizers\n",
    "from tensorflow.keras import layers, models, callbacks, utils"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c2ecbea1-6930-47f9-99f3-4526cc40a746",
   "metadata": {},
   "source": [
    "### file loading and hyperparameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "b1cb764f-70ee-475f-b06a-adf18e9be083",
   "metadata": {},
   "outputs": [],
   "source": [
    "filemap = {\n",
    "    'motor_off': 'motor_off.xlsx',\n",
    "    'motor_on': 'motor_on.xlsx',\n",
    "    'motor_on_nofan': 'motor_on_nofan.xlsx',\n",
    "    'motor_on_badfan': 'motor_on_badfan.xlsx'\n",
    "}\n",
    "data_columns = ['ax','ay','az','gx','gy','gz']\n",
    "label_column = 'class_label'\n",
    "time_column = 'timestamp'\n",
    "fs = 40.0\n",
    "\n",
    "window_size = 256\n",
    "step = 128\n",
    "\n",
    "test_size = 0.2\n",
    "val_size = 0.1\n",
    "\n",
    "batch_size = 64\n",
    "epochs = 60"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "a3cb15cb-1293-458b-931c-aa93e0f59d1c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "combined shape: (144000, 8)\n"
     ]
    }
   ],
   "source": [
    "frames = []\n",
    "\n",
    "for label,fname in filemap.items():\n",
    "    df = pd.read_excel(fname)\n",
    "    frames.append(df)\n",
    "\n",
    "df = pd.concat(frames)\n",
    "print ('combined shape:', df.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c7eb949c-1600-49ee-b9b4-bdb2c11d83e2",
   "metadata": {},
   "source": [
    "## preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e8e9bd15-642b-4e21-b5b7-a00610330199",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Windowing raw signals into model-ready arrays\n",
    "# Creating sliding windows without label-mixing: taking contiguous windows and assigning them\n",
    "# the most-common label within the window (majority vote). This avoids feature engineering.\n",
    "\n",
    "# Create numpy arrays from sensors and labels\n",
    "sensors_arr = df_all[SENSOR_COLUMNS].values.astype('float32')\n",
    "labels_arr = df_all[LABEL_COLUMN].values\n",
    "\n",
    "print('Sensors shape (samples, channels):', sensors_arr.shape)\n",
    "\n",
    "# Sliding window generator\n",
    "def make_windows(data, labels, window_size=WINDOW_SIZE, step=STEP):\n",
    "    X = []\n",
    "    y = []\n",
    "    n_samples = data.shape[0]\n",
    "    for start in range(0, n_samples - window_size + 1, step):\n",
    "        end = start + window_size\n",
    "        win = data[start:end]\n",
    "        lab_win = labels[start:end]\n",
    "        # majority label in the window\n",
    "        vals, counts = np.unique(lab_win, return_counts=True)\n",
    "        label = vals[np.argmax(counts)]\n",
    "        X.append(win)\n",
    "        y.append(label)\n",
    "    X = np.array(X)\n",
    "    y = np.array(y)\n",
    "    return X, y\n",
    "\n",
    "X, y = make_windows(sensors_arr, labels_arr, WINDOW_SIZE, STEP)\n",
    "print('Windows created: X shape =', X.shape, 'y shape =', y.shape)\n",
    "\n",
    "# Encode labels to 0..n-1\n",
    "le = LabelEncoder()\n",
    "y_enc = le.fit_transform(y)\n",
    "print('Label classes:', le.classes_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b9bd01f-8ea5-4c82-a737-0c86e9908a30",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train/test split (stratified by window label)\n",
    "X_trainval, X_test, y_trainval, y_test = train_test_split(\n",
    "    X, y_enc, test_size=TEST_SIZE, random_state=SEED, stratify=y_enc\n",
    ")\n",
    "# Further split train->train+val\n",
    "X_train, X_val, y_train, y_val = train_test_split(\n",
    "    X_trainval, y_trainval, test_size=VAL_SIZE, random_state=SEED, stratify=y_trainval\n",
    ")\n",
    "\n",
    "print('Train/Val/Test shapes:', X_train.shape, X_val.shape, X_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5119dc83-62a7-40d2-9406-858acc92b80b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Scale channels using StandardScaler fit on train windows (fit per channel across all windows/timepoints)\n",
    "# Reshaping to (n_windows * window_size, n_channels) to fit scaler and then reshape back.\n",
    "\n",
    "n_channels = X.shape[2]\n",
    "scaler = StandardScaler()\n",
    "reshaped = X_train.reshape(-1, n_channels)\n",
    "scaler.fit(reshaped)\n",
    "\n",
    "# transform datasets\n",
    "X_train_scaled = scaler.transform(X_train.reshape(-1, n_channels)).reshape(X_train.shape)\n",
    "X_val_scaled = scaler.transform(X_val.reshape(-1, n_channels)).reshape(X_val.shape)\n",
    "X_test_scaled = scaler.transform(X_test.reshape(-1, n_channels)).reshape(X_test.shape)\n",
    "\n",
    "# Convert labels to categorical\n",
    "num_classes = len(le.classes_)\n",
    "y_train_cat = utils.to_categorical(y_train, num_classes)\n",
    "y_val_cat = utils.to_categorical(y_val, num_classes)\n",
    "y_test_cat = utils.to_categorical(y_test, num_classes)\n",
    "\n",
    "# For Keras: ensure dtype float32\n",
    "X_train_scaled = X_train_scaled.astype('float32')\n",
    "X_val_scaled = X_val_scaled.astype('float32')\n",
    "X_test_scaled = X_test_scaled.astype('float32')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "298bc8f5-c0cf-48b6-b415-97eef71ded62",
   "metadata": {},
   "source": [
    "## Model Architecture"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84952f39-8515-4700-a0e4-2a7678cbef92",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1D-CNN backbone -> DNN (Dense layers)\n",
    "\n",
    "model = models.Sequential([\n",
    "    layers.Input(shape=(WINDOW_SIZE, n_channels)),\n",
    "\n",
    "    layers.Conv1D(32, kernel_size=7, padding='same', kernel_regularizer=regularizers.l2(1e-4)),\n",
    "    layers.BatchNormalization(),\n",
    "    layers.Activation('relu'),\n",
    "    layers.SpatialDropout1D(0.2),\n",
    "    layers.MaxPooling1D(2),\n",
    "\n",
    "    layers.Conv1D(64, kernel_size=5, padding='same', kernel_regularizer=regularizers.l2(1e-4)),\n",
    "    layers.BatchNormalization(),\n",
    "    layers.Activation('relu'),\n",
    "    layers.SpatialDropout1D(0.25),\n",
    "    layers.MaxPooling1D(2),\n",
    "\n",
    "    layers.Conv1D(128, kernel_size=3, padding='same', kernel_regularizer=regularizers.l2(1e-4)),\n",
    "    layers.BatchNormalization(),\n",
    "    layers.Activation('relu'),\n",
    "    layers.GlobalAveragePooling1D(),\n",
    "\n",
    "    layers.Dense(256, kernel_regularizer=regularizers.l2(1e-4)),\n",
    "    layers.BatchNormalization(),\n",
    "    layers.Activation('relu'),\n",
    "    layers.Dropout(0.5),\n",
    "\n",
    "    layers.Dense(num_classes, activation='softmax')\n",
    "])\n",
    "\n",
    "model.compile(\n",
    "    optimizer=tf.keras.optimizers.Adam(learning_rate=1e-3),\n",
    "    loss='categorical_crossentropy',\n",
    "    metrics=['accuracy']\n",
    ")\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a4334fcc-4851-41d3-b355-64be6c004292",
   "metadata": {},
   "source": [
    "## Model Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b63863f-be3d-4516-9509-7c3829d02e16",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training\n",
    "\n",
    "# Callbacks\n",
    "es = callbacks.EarlyStopping(monitor='val_loss', patience=8, restore_best_weights=True)\n",
    "rl = callbacks.ReduceLROnPlateau(monitor='val_loss', factor=0.5, patience=8, min_lr=1e-6)\n",
    "\n",
    "\n",
    "history = model.fit(\n",
    "X_train_scaled, y_train_cat,\n",
    "validation_data=(X_val_scaled, y_val_cat),\n",
    "epochs=EPOCHS,\n",
    "batch_size=BATCH_SIZE,\n",
    "callbacks=[es, rl]\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5d63e8cf-6bd8-41b0-98d5-ad669cde3729",
   "metadata": {},
   "source": [
    "## Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b65cdc3-c0e7-41d6-802d-39b431a9b321",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot training curves\n",
    "plt.figure(figsize=(12,4))\n",
    "plt.subplot(1,2,1)\n",
    "plt.plot(history.history['loss'], label='train_loss')\n",
    "plt.plot(history.history['val_loss'], label='val_loss')\n",
    "plt.legend(); plt.title('Loss')\n",
    "plt.subplot(1,2,2)\n",
    "plt.plot(history.history['accuracy'], label='train_acc')\n",
    "plt.plot(history.history['val_accuracy'], label='val_acc')\n",
    "plt.legend(); plt.title('Accuracy')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db23fe54-e07e-4504-a451-4879420720ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Using trained model from this session (no disk loading since saving was disabled)\n",
    "best = model\n",
    "\n",
    "# Evaluate on test set\n",
    "test_loss, test_acc = best.evaluate(X_test_scaled, y_test_cat, verbose=0)\n",
    "print(f'Test loss: {test_loss:.4f}, Test accuracy: {test_acc:.4f}')\n",
    "\n",
    "# Predictions -> classification report\n",
    "y_pred_probs = best.predict(X_test_scaled)\n",
    "y_pred = np.argmax(y_pred_probs, axis=1)\n",
    "\n",
    "print('\\nClassification report:')\n",
    "print(classification_report(y_test, y_pred, target_names=[str(c) for c in le.classes_]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e695b0f-0bcd-4b2b-b134-f5b8c470ea3a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Confusion matrix\n",
    "cm = confusion_matrix(y_test, y_pred)\n",
    "plt.figure(figsize=(6,5))\n",
    "sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', xticklabels=le.classes_, yticklabels=le.classes_)\n",
    "plt.xlabel('Predicted')\n",
    "plt.ylabel('True')\n",
    "plt.title('Confusion Matrix')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f4ae9fee-3bd7-4d91-bfbe-60880a825e82",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
